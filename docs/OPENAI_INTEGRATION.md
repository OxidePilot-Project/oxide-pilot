# OpenAI Integration Guide

## Overview

Oxide Pilot integrates OpenAI's GPT-4o model as a collaborative AI provider using API Key authentication. This provides powerful language understanding and generation capabilities for system analysis, threat detection, and intelligent automation.

## Authentication Method

**API Key Only**: OpenAI integration uses API Key authentication (not OAuth). This is simpler and more suitable for desktop applications.

## Configuration

### Environment Variable (Recommended for Development)

```bash
# In src-tauri/.env
OPENAI_API_KEY=sk-proj-...your-api-key...
```

### UI Configuration (Recommended for End Users)

1. Open Oxide Pilot Settings
2. Navigate to "AI Providers" section
3. Select "OpenAI" tab
4. Enter your API Key
5. Click "Save"

The API key is securely stored in your system's keyring (Windows Credential Manager, macOS Keychain, or Linux Secret Service).

## Supported Models

- **gpt-4o** (default): Latest GPT-4 Optimized model with vision capabilities
- **gpt-4o-mini**: Faster, more cost-effective variant
- **gpt-4-turbo**: Previous generation with strong performance

## Usage in Collaborative System

OpenAI can be used as:

1. **Primary Provider**: Main AI for all tasks
2. **Secondary Provider**: Backup when Gemini is unavailable
3. **Consensus Provider**: Second opinion for threat analysis

### Example: Dual Provider Consensus

```rust
use oxide_copilot::collaborative_providers::CollaborativeProviderFactory;
use oxide_copilot::llm_orchestrator::{LLMOrchestrator, LLMRole};

let mut orchestrator = LLMOrchestrator::new();

// Add Gemini as primary
orchestrator.add_provider(
    "gemini".to_string(),
    CollaborativeProviderFactory::create_gemini(LLMRole::Coordinator, None),
    config_gemini,
);

// Add OpenAI as secondary/validator
orchestrator.add_provider(
    "openai".to_string(),
    CollaborativeProviderFactory::create_openai(LLMRole::Validator, Some("gpt-4o".to_string())),
    config_openai,
);

// Execute collaborative task
let result = orchestrator.execute_collaborative_task(
    "Analyze system security",
    context,
).await?;
```

## API Key Management

### Obtaining an API Key

1. Visit [OpenAI Platform](https://platform.openai.com/)
2. Sign up or log in
3. Navigate to API Keys section
4. Create a new API key
5. Copy and save it securely (you won't see it again)

### Security Best Practices

- **Never commit API keys to version control**
- Store keys in environment variables or system keyring
- Rotate keys periodically
- Use separate keys for development and production
- Monitor usage on OpenAI dashboard

### Key Storage Locations

- **Environment**: `OPENAI_API_KEY` variable
- **Keyring**: Service: `oxide_pilot_openai`, Field: `api_key`
- **Priority**: Environment variable takes precedence over keyring

## Features

### Collaborative Roles

OpenAI can fulfill any collaborative role:

- **Coordinator**: Primary task orchestration
- **Analyst**: Deep technical analysis
- **Executor**: System command generation
- **Innovator**: Creative problem solving
- **Validator**: Response quality checking

### Capabilities

- Natural language understanding
- Code generation and analysis
- System command suggestions
- Threat assessment
- Performance optimization recommendations
- Multi-turn conversations with context

## Troubleshooting

### "No OpenAI API key configured"

**Solution**: Set `OPENAI_API_KEY` environment variable or configure via UI.

### "API error: 401 Unauthorized"

**Cause**: Invalid or expired API key.

**Solution**:
1. Verify your API key is correct
2. Check if key has been revoked on OpenAI dashboard
3. Generate a new key if needed

### "API error: 429 Too Many Requests"

**Cause**: Rate limit exceeded.

**Solution**:
1. Check your usage on OpenAI dashboard
2. Upgrade your plan if needed
3. Implement request throttling in your application

### "API error: 500 Internal Server Error"

**Cause**: OpenAI service issue.

**Solution**:
1. Check [OpenAI Status Page](https://status.openai.com/)
2. Wait and retry
3. Fall back to alternative provider (Gemini/Qwen)

## Cost Considerations

OpenAI API usage is billed per token:

- **Input tokens**: Text sent to the API
- **Output tokens**: Text generated by the API

### Estimated Costs (as of 2024)

- **gpt-4o**: ~$5 per 1M input tokens, ~$15 per 1M output tokens
- **gpt-4o-mini**: ~$0.15 per 1M input tokens, ~$0.60 per 1M output tokens

### Cost Optimization Tips

1. Use `gpt-4o-mini` for simpler tasks
2. Set reasonable `max_tokens` limits
3. Cache responses when appropriate
4. Use streaming for long responses
5. Monitor usage regularly

## API Reference

### Tauri Commands

```typescript
// Set API key
await invoke('openai_set_api_key', { api_key: 'sk-...' });

// Get authentication status
const status = await invoke('openai_get_auth_status');

// Clear API key
await invoke('openai_clear_auth');
```

### Rust API

```rust
use oxide_core::openai_client::{chat_completion, ChatMessage};

let messages = vec![
    ChatMessage {
        role: "system".to_string(),
        content: "You are a helpful assistant.".to_string(),
    },
    ChatMessage {
        role: "user".to_string(),
        content: "Analyze this system log...".to_string(),
    },
];

let response = chat_completion(
    "gpt-4o",
    messages,
    Some(0.7),  // temperature
    Some(2000), // max_tokens
).await?;
```

## Environment Variables

```bash
# Required
OPENAI_API_KEY=sk-proj-...

# Optional
OPENAI_API_BASE=https://api.openai.com/v1  # Custom endpoint (for proxies)
```

## Integration with Threat Consensus

OpenAI can be used in the threat consensus engine for dual-provider validation:

```rust
// If both Gemini and OpenAI are available
let gemini_assessment = gemini_provider.analyze_threat(file_path).await?;
let openai_assessment = openai_provider.analyze_threat(file_path).await?;

// Combine assessments with weighted consensus
let final_score = (gemini_assessment.risk_score * 0.6) +
                  (openai_assessment.risk_score * 0.4);
```

## Future Enhancements

- [ ] Function calling support for tool use
- [ ] Vision API integration for screenshot analysis
- [ ] Streaming responses for real-time feedback
- [ ] Fine-tuned models for specific tasks
- [ ] Embeddings for semantic search

## Related Documentation

- [OAuth Setup Guide](OAUTH_SETUP.md) - For Gemini and Qwen
- [Collaborative LLM System](COLLABORATIVE_LLM_SYSTEM.md)
- [Environment Setup](ENVIRONMENT_SETUP.md)

## Support

For issues or questions:
- Check OpenAI [API Documentation](https://platform.openai.com/docs)
- Review [OpenAI Community Forum](https://community.openai.com/)
- File an issue in Oxide Pilot repository
